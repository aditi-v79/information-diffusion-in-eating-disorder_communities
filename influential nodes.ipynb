{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","https://ar5iv.labs.arxiv.org/html/1201.4145\n","\n","---\n","\n"],"metadata":{"id":"emjErRvri1WJ"}},{"cell_type":"code","source":["import networkx as nx\n","import pandas as pd\n","import random\n","from google.colab import drive\n","import xml.etree.ElementTree as ET\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Load GraphML data\n","graphml_file_path = '/content/drive/MyDrive/ed_proj/network.graphml'\n","\n","# Create a directed graph\n","G = nx.DiGraph()\n","\n","tree = ET.parse(graphml_file_path)\n","root = tree.getroot()\n","graphml_ns = {'g': 'http://graphml.graphdrawing.org/xmlns'}\n","\n","# Extract nodes with attributes\n","for node in root.findall(\".//g:node\", namespaces=graphml_ns):\n","    node_id = node.get('id')\n","    name = node.find(\"g:data[@key='v_name']\", namespaces=graphml_ns).text\n","    cluster = int(node.find(\"g:data[@key='v_cluster']\", namespaces=graphml_ns).text)\n","    G.add_node(node_id, name=name, cluster=cluster)\n","\n","# Extract edges with weights\n","for edge in root.findall(\".//g:edge\", namespaces=graphml_ns):\n","    source = edge.get('source')\n","    target = edge.get('target')\n","    weight = float(edge.find(\"g:data[@key='e_weight']\", namespaces=graphml_ns).text)\n","    G.add_edge(source, target, weight=weight)\n","\n","\n","edge_betweenness = nx.edge_betweenness_centrality(G)\n","threshold = sorted(edge_betweenness.values(), reverse=True)[int(len(edge_betweenness) * 0.05)]  # Top 5% as threshold\n","eb_ties = [edge for edge, value in edge_betweenness.items() if value >= threshold]\n","eb_tie_nodes = set()\n","for edge in eb_ties:\n","    eb_tie_nodes.update(edge)\n","\n","# Identify Pro-ED nodes and calculate centralities\n","pro_ed_nodes = [node for node, attr in G.nodes(data=True) if attr['cluster'] == 0]\n","degree_centrality = nx.in_degree_centrality(G)\n","betweenness_centrality = nx.betweenness_centrality(G)\n","closeness_centrality = nx.closeness_centrality(G)\n","eigenvector_centrality = nx.eigenvector_centrality(G)\n","pagerank = nx.pagerank(G)\n","\n","# Number of starting nodes for each method\n","num_start_nodes = 100\n","\n","# Select the top nodes for each centrality measure\n","top_degree = sorted(degree_centrality, key=degree_centrality.get, reverse=True)[:num_start_nodes]\n","top_betweenness = sorted(betweenness_centrality, key=betweenness_centrality.get, reverse=True)[:num_start_nodes]\n","top_closeness = sorted(closeness_centrality, key=closeness_centrality.get, reverse=True)[:num_start_nodes]\n","top_eigenvector = sorted(eigenvector_centrality, key=eigenvector_centrality.get, reverse=True)[:num_start_nodes]\n","top_pagerank = sorted(pagerank, key=pagerank.get, reverse=True)[:num_start_nodes]\n","\n","\n","eb_tie_nodes = list(eb_tie_nodes)[:num_start_nodes]\n","\n","\n","\n","# Merge Degree and Weak Tie nodes (maintaining equal number)\n","starting_nodes_with_edge_betweeness = set(top_degree[:num_start_nodes//2])  # Half from degree centrality\n","starting_nodes_with_edge_betweeness.update(eb_tie_nodes[:num_start_nodes//2])  # Half from weak ties\n","\n","# Merge PageRank and Betweenness nodes (maintaining equal number)\n","starting_nodes_with_page_rank_and_betweenness = set(top_pagerank[:num_start_nodes//2])  # Half from PageRank\n","starting_nodes_with_page_rank_and_betweenness.update(top_betweenness[:num_start_nodes//2])  # Half from betweenness\n","\n","# Information Diffusion Simulation\n","def simulate_diffusion_pro_ed(G, start_nodes, steps=5):\n","    reached_nodes = set(start_nodes)  # Nodes that have received information\n","    frontier = set(start_nodes)      # Nodes that will spread information in the next step\n","\n","    for _ in range(steps):\n","        if not frontier:  # Stop if there are no more nodes to spread to\n","            break\n","        next_frontier = set()  # Nodes that will spread information in the next step\n","        for node in frontier:\n","            for neighbor in G.predecessors(node):\n","                if neighbor in pro_ed_nodes and neighbor not in reached_nodes:\n","                    if random.random() < 0.50:  # 50% chance to spread information\n","                        reached_nodes.add(neighbor)\n","                        next_frontier.add(neighbor)\n","        frontier = next_frontier  # Update the frontier\n","\n","    return len(frontier), reached_nodes  # Return the number of steps and the set of reached nodes\n","\n","\n","\n","# Run simulations with equal number of starting nodes for all methods\n","results = []\n","for method, nodes in [('Degree', top_degree), ('Betweenness', top_betweenness),\n","                      ('Closeness', top_closeness), ('Eigenvector', top_eigenvector),\n","                      ('PageRank', top_pagerank),\n","                      ('Degree with edge betweeness', list(starting_nodes_with_edge_betweeness)), ('nodes_with_page_rank_and_betweennes', list(starting_nodes_with_page_rank_and_betweenness))]:\n","    steps_taken, reached_nodes = simulate_diffusion_pro_ed(G, nodes, steps=5)\n","    results.append({'Method': method, 'Steps': steps_taken, 'Nodes Reached': len(reached_nodes), 'Average per step': len(reached_nodes)/(steps_taken+1)})\n","\n","# Convert results to a DataFrame for comparison\n","results_df = pd.DataFrame(results)\n","print(results_df)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yFPn2Py1vmzf","executionInfo":{"status":"ok","timestamp":1701045182373,"user_tz":300,"elapsed":157654,"user":{"displayName":"Amarthya Sivakumar Annu","userId":"12262139972053559626"}},"outputId":"4f8a0dfc-0660-4455-85ed-9b67fe654ffb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","                                Method  Steps  Nodes Reached  Average per step\n","0                               Degree      2           1905        635.000000\n","1                          Betweenness      0            634        634.000000\n","2                            Closeness      3           1599        399.750000\n","3                          Eigenvector      0            116        116.000000\n","4                             PageRank      1           1787        893.500000\n","5          Degree with edge betweeness      0           1819       1819.000000\n","6  nodes_with_page_rank_and_betweennes      2           1676        558.666667\n"]}]},{"cell_type":"code","source":["# Number of starting nodes for each method\n","num_start_nodes = 60\n","\n","# Select the top nodes for each centrality measure\n","top_degree = sorted(degree_centrality, key=degree_centrality.get, reverse=True)[:num_start_nodes]\n","top_betweenness = sorted(betweenness_centrality, key=betweenness_centrality.get, reverse=True)[:num_start_nodes]\n","top_closeness = sorted(closeness_centrality, key=closeness_centrality.get, reverse=True)[:num_start_nodes]\n","top_eigenvector = sorted(eigenvector_centrality, key=eigenvector_centrality.get, reverse=True)[:num_start_nodes]\n","top_pagerank = sorted(pagerank, key=pagerank.get, reverse=True)[:num_start_nodes]\n","\n","\n","eb_tie_nodes = list(eb_tie_nodes)[:num_start_nodes]\n","\n","\n","\n","# Merge Degree and Weak Tie nodes (maintaining equal number)\n","starting_nodes_with_edge_betweeness = set(top_degree[:num_start_nodes//2])  # Half from degree centrality\n","starting_nodes_with_edge_betweeness.update(eb_tie_nodes[:num_start_nodes//2])  # Half from weak ties\n","\n","# Merge PageRank and Betweenness nodes (maintaining equal number)\n","starting_nodes_with_page_rank_and_betweenness = set(top_pagerank[:num_start_nodes//2])  # Half from PageRank\n","starting_nodes_with_page_rank_and_betweenness.update(top_betweenness[:num_start_nodes//2])  # Half from betweenness\n","\n","# Information Diffusion Simulation\n","def simulate_diffusion_pro_ed(G, start_nodes, steps=5):\n","    reached_nodes = set(start_nodes)  # Nodes that have received information\n","    frontier = set(start_nodes)      # Nodes that will spread information in the next step\n","\n","    for _ in range(steps):\n","        if not frontier:  # Stop if there are no more nodes to spread to\n","            break\n","        next_frontier = set()  # Nodes that will spread information in the next step\n","        for node in frontier:\n","            for neighbor in G.predecessors(node):\n","                if neighbor in pro_ed_nodes and neighbor not in reached_nodes:\n","                    if random.random() < 0.50:  # 50% chance to spread information\n","                        reached_nodes.add(neighbor)\n","                        next_frontier.add(neighbor)\n","        frontier = next_frontier  # Update the frontier\n","\n","    return len(frontier), reached_nodes  # Return the number of steps and the set of reached nodes\n","\n","\n","\n","# Run simulations with equal number of starting nodes for all methods\n","results = []\n","for method, nodes in [('Degree', top_degree), ('Betweenness', top_betweenness),\n","                      ('Closeness', top_closeness), ('Eigenvector', top_eigenvector),\n","                      ('PageRank', top_pagerank),\n","                      ('Degree with edge betweeness', list(starting_nodes_with_edge_betweeness)), ('nodes_with_page_rank_and_betweennes', list(starting_nodes_with_page_rank_and_betweenness))]:\n","    steps_taken, reached_nodes = simulate_diffusion_pro_ed(G, nodes, steps=5)\n","    results.append({'Method': method, 'Steps': steps_taken, 'Nodes Reached': len(reached_nodes), 'Average per step': len(reached_nodes)/(steps_taken+1)})\n","\n","# Convert results to a DataFrame for comparison\n","results_df = pd.DataFrame(results)\n","print(results_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i6o30BhUXIsM","executionInfo":{"status":"ok","timestamp":1701044493733,"user_tz":300,"elapsed":3391,"user":{"displayName":"Amarthya Sivakumar Annu","userId":"12262139972053559626"}},"outputId":"778aa5ba-b500-42db-99e7-0794339e7942"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                Method  Steps  Nodes Reached  Average per step\n","0                               Degree      2           1806        602.000000\n","1                          Betweenness      5            557         92.833333\n","2                            Closeness     16           1419         83.470588\n","3                          Eigenvector      0             73         73.000000\n","4                             PageRank      2           1757        585.666667\n","5          Degree with edge betweeness      4           1623        324.600000\n","6  nodes_with_page_rank_and_betweennes     11           1552        129.333333\n"]}]},{"cell_type":"code","source":["# Number of starting nodes for each method\n","num_start_nodes = 50\n","\n","# Select the top nodes for each centrality measure\n","top_degree = sorted(degree_centrality, key=degree_centrality.get, reverse=True)[:num_start_nodes]\n","top_betweenness = sorted(betweenness_centrality, key=betweenness_centrality.get, reverse=True)[:num_start_nodes]\n","top_closeness = sorted(closeness_centrality, key=closeness_centrality.get, reverse=True)[:num_start_nodes]\n","top_eigenvector = sorted(eigenvector_centrality, key=eigenvector_centrality.get, reverse=True)[:num_start_nodes]\n","top_pagerank = sorted(pagerank, key=pagerank.get, reverse=True)[:num_start_nodes]\n","\n","\n","eb_tie_nodes = list(eb_tie_nodes)[:num_start_nodes]\n","\n","\n","\n","# Merge Degree and Weak Tie nodes (maintaining equal number)\n","starting_nodes_with_edge_betweeness = set(top_degree[:num_start_nodes//2])  # Half from degree centrality\n","starting_nodes_with_edge_betweeness.update(eb_tie_nodes[:num_start_nodes//2])  # Half from weak ties\n","\n","# Merge PageRank and Betweenness nodes (maintaining equal number)\n","starting_nodes_with_page_rank_and_betweenness = set(top_pagerank[:num_start_nodes//2])  # Half from PageRank\n","starting_nodes_with_page_rank_and_betweenness.update(top_betweenness[:num_start_nodes//2])  # Half from betweenness\n","\n","# Information Diffusion Simulation\n","def simulate_diffusion_pro_ed(G, start_nodes, steps=5):\n","    reached_nodes = set(start_nodes)  # Nodes that have received information\n","    frontier = set(start_nodes)      # Nodes that will spread information in the next step\n","\n","    for _ in range(steps):\n","        if not frontier:  # Stop if there are no more nodes to spread to\n","            break\n","        next_frontier = set()  # Nodes that will spread information in the next step\n","        for node in frontier:\n","            for neighbor in G.predecessors(node):\n","                if neighbor in pro_ed_nodes and neighbor not in reached_nodes:\n","                    if random.random() < 0.50:  # 50% chance to spread information\n","                        reached_nodes.add(neighbor)\n","                        next_frontier.add(neighbor)\n","        frontier = next_frontier  # Update the frontier\n","\n","    return len(frontier), reached_nodes  # Return the number of steps and the set of reached nodes\n","\n","\n","\n","# Run simulations with equal number of starting nodes for all methods\n","results = []\n","for method, nodes in [('Degree', top_degree), ('Betweenness', top_betweenness),\n","                      ('Closeness', top_closeness), ('Eigenvector', top_eigenvector),\n","                      ('PageRank', top_pagerank),\n","                      ('Degree with edge betweeness', list(starting_nodes_with_edge_betweeness)), ('nodes_with_page_rank_and_betweennes', list(starting_nodes_with_page_rank_and_betweenness))]:\n","    steps_taken, reached_nodes = simulate_diffusion_pro_ed(G, nodes, steps=5)\n","    results.append({'Method': method, 'Steps': steps_taken, 'Nodes Reached': len(reached_nodes), 'Average per step': len(reached_nodes)/(steps_taken+1)})\n","\n","# Convert results to a DataFrame for comparison\n","results_df = pd.DataFrame(results)\n","print(results_df)\n","\n","#"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k5UQN3MsXQDr","executionInfo":{"status":"ok","timestamp":1701044495967,"user_tz":300,"elapsed":2237,"user":{"displayName":"Amarthya Sivakumar Annu","userId":"12262139972053559626"}},"outputId":"56458b03-b023-41c5-c70c-1a32d1a1624b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                Method  Steps  Nodes Reached  Average per step\n","0                               Degree      2           1755        585.000000\n","1                          Betweenness      4            546        109.200000\n","2                            Closeness      4           1332        266.400000\n","3                          Eigenvector      0             64         64.000000\n","4                             PageRank     10           1616        146.909091\n","5          Degree with edge betweeness      1           1504        752.000000\n","6  nodes_with_page_rank_and_betweennes      8           1365        151.666667\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"QCTESYIJWEGB"},"execution_count":null,"outputs":[]}]}